{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from imutils.video import VideoStream\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_predict_mask(frame , faceNet , maskNet): #( video frame ,facedetect model,mobilenet_v2 model)\n",
    "    # taking then dims of frame and construct the blob\n",
    "    (h,w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0,(300,300),(104.0,177.0,123.0))# resize the image (RGB only)\n",
    "    faceNet.setInput(blob)  \n",
    "    detections = faceNet.forward()\n",
    "    \n",
    "    #initialize our list of faces , their corresponding locations and list of predictions\n",
    "    faces = []\n",
    "    locs =[]\n",
    "    preds = []\n",
    "    \n",
    "    for i in range(0,detections.shape[2]):\n",
    "            confidence = detections[0 ,0 ,i ,2]\n",
    "        #     print(\"confidence: \" ,confidence)\n",
    "            if confidence> 0.5:\n",
    "                # getting the x and y coordinates \n",
    "                box = detections[0,0,i,3:7]*np.array([w,h,w,h])\n",
    "                (startx , starty , endx , endy) = box.astype('int')\n",
    "                (startx , starty)=(max(0 , startx) , max(0 ,starty))\n",
    "                (endx , endy) = (min(w-1, endx) , min(h-1,endy))\n",
    "                #Extract the face ROI , convert it from BRG to RGB channel , resize it to (224x224) and preprocess it\n",
    "                face = frame[starty:endy , startx:endx]\n",
    "                face = cv2.cvtColor(face , cv2.COLOR_BGR2RGB)\n",
    "                face= cv2.resize(face,(224,224))\n",
    "                face = img_to_array(face)\n",
    "                face = preprocess_input(face)\n",
    "\n",
    "                faces.append(face)\n",
    "                locs.append((startx , starty , endx , endy))\n",
    "   \n",
    "        # only make a prediction if atleast one face was detected\n",
    "            if len(faces)>0:\n",
    "                faces= np.array(faces , dtype ='float32')\n",
    "                preds = maskNet.predict(faces , batch_size =12)\n",
    "            return (locs , preds)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing face detectors\n",
    "protoPath = os.path.sep.join([r'C:\\Users\\Ritika Singh\\Desktop\\Corona Virus Mask Detection','deploys.prototxt'])\n",
    "weightsPath = os.path.sep.join([r'C:\\Users\\Ritika Singh\\Desktop\\Corona Virus Mask Detection','res10_300x300_ssd_iter_140000.caffemodel'])\n",
    "faceNet = cv2.dnn.readNet(protoPath,weightsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskNet = load_model(r'C:\\Users\\Ritika Singh\\Desktop\\Corona Virus Mask Detection\\my_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = VideoStream(src = 0).start()\n",
    "\n",
    "while True :\n",
    "    # grab the frame from the threaded video stream and resize it to have maximum of 400  pixels\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame , width = 400)\n",
    "    # detect and predict\n",
    "    (locs , preds) = detect_and_predict_mask(frame , faceNet , maskNet)\n",
    "    # loop over the face detected face locations and their corresponding locations\n",
    "    \n",
    "    for (box , pred )  in zip(locs , preds):\n",
    "        (startx , starty , endx , endy) = box\n",
    "        (mask, without_mask) =pred\n",
    "        #determine the class label and color we will use to draw the bounding box and text\n",
    "        label = \"Mask\" if mask>without_mask else \"No Mask\"\n",
    "        color = (0,255,0) if label == 'Mask' else (0,0,255)\n",
    "        #Including the probability in label\n",
    "\n",
    "        label =\"{} : {:.2f}%\".format(label , max(mask ,without_mask)*100)\n",
    "        \n",
    "        # Display the label and bounding boxes\n",
    "        \n",
    "        cv2.putText(frame, label ,(startx ,starty-10) , cv2.FONT_HERSHEY_SIMPLEX , 0.45 , color,2)# diplay the text below\n",
    "        cv2.rectangle(frame ,(startx ,starty),(endx, endy) , color , 2)\n",
    "    \n",
    "     # show the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1)& 0xFF #wait for some milliseconds\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
